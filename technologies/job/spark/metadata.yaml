version: "v1"
type: JOB
id: spark
label: Spark for AWS
description: Spark for AWS (S3 and Kinesis connectors)
available: true
icon: spark
customFlags: [Spark]

contexts:
  - id: 3.0
    label: 3.0
    available: true
    recommended: false
    trustLevel: stable
    dockerInfo:
      image: saagie/spark
      baseTag: 3.0-aws
      version: 3.0-aws-1.20.0
    innerContexts:
      - id: java-scala
        label: Java/Scala
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: spark-submit --class=Main {file} arg1 arg2
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .jar"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: 11
            label: 11
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.0-aws-jre-11
              version: 3.0-aws-jre-11-1.20.0
      - id: python
        label: Python
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: spark-submit --py-files={file} __main__.py
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .py or .zip"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: 3.7
            label: 3.7
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.0-aws-py-3.7
              version: 3.0-aws-py-3.7-1.20.0
  - id: 3.1
    label: 3.1
    available: true
    recommended: true
    trustLevel: stable
    dockerInfo:
      image: saagie/spark
      baseTag: 3.1-aws
      version: 3.1-aws-1.20.1
    innerContexts:
      - id: java-scala
        label: Java/Scala
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: spark-submit --class=Main {file} arg1 arg2
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .jar"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: 11
            label: 11
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.1-aws-jre-11
              version: 3.1-aws-jre-11-1.20.1
      - id: python
        label: Python
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: spark-submit --py-files={file} local://__main__.py
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .py or .zip"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: 3.7
            label: 3.7
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.1-aws-py-3.7
              version: 3.1-aws-py-3.7-1.20.1