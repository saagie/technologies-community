version: "v1"
type: JOB
id: spark
label: Spark for AWS
description: Spark for AWS (S3 connectors)
available: true
icon: spark
customFlags: [Spark]

contexts:
  - id: "3.2"
    label: "3.2"
    description: Spark 3.2 for AWS (S3 connector)
    available: true
    recommended: true
    trustLevel: stable
    dockerInfo:
      image: saagie/spark
      baseTag: 3.2-aws
      version: 3.2-aws-0.36
    innerContexts:
      - id: java-scala
        label: Java/Scala
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: "spark-submit --conf spark.executor.cores=1 --conf spark.executor.instances=2 --conf spark.executor.memory=2g --conf spark.driver.memory=1g --class=Main {file}"
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .jar"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: "11"
            label: "11"
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.2-aws-jre-11
              version: 3.2-aws-jre-11-0.36
      - id: python
        label: Python
        available: true
        trustLevel: stable
        job:
          features:
            - type: COMMAND_LINE
              label: Command line
              mandatory: true
              comment: Linux shell command to launch the job.
              defaultValue: "spark-submit --py-files={file} --conf spark.executor.cores=1 --conf spark.executor.instances=2 --conf spark.executor.memory=2g --conf spark.driver.memory=1g --name app-name local://__main__.py"
            - type: ARTIFACT
              label: Package
              mandatory: true
              comment: "Compatible upload file : .py or .zip"
            - type: SCHEDULER
              label: Scheduled
              mandatory: true
        innerContexts:
          - id: "3.8"
            label: "3.8"
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.2-aws-py-3.8
              version: 3.2-aws-py-3.8-0.36
          - id: "3.9"
            label: "3.9"
            available: true
            trustLevel: stable
            dockerInfo:
              image: saagie/spark
              baseTag: 3.2-aws-py-3.9
              version: 3.2-aws-py-3.9-0.36